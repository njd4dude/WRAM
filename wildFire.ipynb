{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njd4dude/WRAM/blob/main/wildFire.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jRgVeF7N5-NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hornet Hacks 2024\n",
        "## Roundtable Rascals\n",
        "## Wildfire Risk Prediction Map Generator\n",
        "\n",
        "# Stage 1: Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "-U42IM7zadUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install and import the necesarry libraries. Since the dataset is stored in hdf5 files we use h5py"
      ],
      "metadata": {
        "id": "dBNzmIVRaoNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install hdf5plugin\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BE4OleuA-r4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mlGJQpis_dBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "eCki22FQ4hOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import hdf5plugin\n",
        "import os\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Conv2D,\\\n",
        "\tMaxPool2D, Conv2DTranspose, Input, Activation,\\\n",
        "\tConcatenate, CenterCrop\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.optimizers import schedules, Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import random\n",
        "from scipy.ndimage import label"
      ],
      "metadata": {
        "id": "JAbWVxUd-uDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the HDF5 file\n",
        "with h5py.File('/content/drive/MyDrive/california_0.hdf5', 'r') as f:\n",
        "    # List all groups\n",
        "    print(\"Keys: %s\" % list(f.keys()))\n",
        "\n",
        "    # Get data from the group '0'\n",
        "    data = f['0']\n",
        "\n",
        "    # List all datasets or subgroups inside the group\n",
        "    print(\"Keys inside group '0': %s\" % list(data.keys()))\n",
        "    print(\"Keys inside group '0' length: %s\" % len(list(data.keys())))\n",
        "\n",
        "    # Access the first instance inside the group '0'\n",
        "    first_instance_key = list(data.keys())[0]  # Get the first key (e.g., '35579f9f-...')\n",
        "    instance_1 = data[first_instance_key]\n",
        "\n",
        "    # List keys in the first instance\n",
        "    print(\"Keys: %s\" % list(instance_1.keys()))\n",
        "    print(instance_1)\n",
        "\n",
        "    # Access 'pre_fire' or 'post_fire' image data\n",
        "     # Access 'pre_fire' and 'post_fire' image data\n",
        "\n",
        "    pre_fire_1 = instance_1['pre_fire'][:]\n",
        "\n",
        "    post_fire_1 = instance_1['post_fire'][:]\n",
        "\n",
        "    mask = instance_1['mask'][:]\n",
        "\n",
        "    print(pre_fire_1.shape)\n",
        "\n",
        "    print(f\"prefire type: \", pre_fire_1.dtype)"
      ],
      "metadata": {
        "id": "XZFByHfl-ud1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot each channel separately\n",
        "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(12):\n",
        "    axes[i].imshow(pre_fire_1[:, :, i], cmap='gray')\n",
        "    axes[i].set_title(f\"Channel {i + 1}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1VWe8skp-wZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the HDF5 file\n",
        "with h5py.File('/content/drive/MyDrive/california_0.hdf5', 'r') as f:\n",
        "    # Access the group '0'\n",
        "    data = f['0']\n",
        "\n",
        "    # Access the first instance inside the group '0'\n",
        "    first_instance_key = list(data.keys())[0]  # Get the first key (e.g., '35579f9f-...')\n",
        "    instance_1 = data[first_instance_key]\n",
        "\n",
        "    # Access 'pre_fire' image data\n",
        "    pre_fire_1 = instance_1['pre_fire'][:]\n",
        "\n",
        "    # Access \"mask\" image data\n",
        "    mask_fire_1 = instance_1['mask'][:]  # This should be just the mask without channel indexing\n",
        "\n",
        "    # Extract one image (for example, the first channel)\n",
        "    channel_to_extract = 9  # Change this index to extract a different channel\n",
        "    image = pre_fire_1[:, :, channel_to_extract]\n",
        "\n",
        "    # Get the coordinates where the mask is equal to 1]\n",
        "    print(f\"mask fire type:{mask_fire_1.dtype} \")\n",
        "    print(f\"mask fire shape:{mask_fire_1.shape}\")\n",
        "    labeled_mask, num_features = label(mask_fire_1)  # Label connected components in the mask\n",
        "\n",
        "    # Set up a figure to display results\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Show the extracted image\n",
        "    axes[0].imshow(image, cmap='gray')\n",
        "    axes[0].set_title(f\"Extracted Image - Channel {channel_to_extract + 1}\")\n",
        "    axes[0].axis('off')  # Hide axis\n",
        "\n",
        "    # Show the mask image\n",
        "    axes[1].imshow(mask_fire_1, cmap='gray')  # Use cmap='gray' for grayscale\n",
        "    axes[1].set_title(\"Mask Image\")\n",
        "    axes[1].axis('off')  # Hide axis\n",
        "\n",
        "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "    plt.show()\n",
        "\n",
        "    target_size = 512  # Desired size for cropped images\n",
        "    if num_features > 0:  # Check if any features were found\n",
        "        for i in range(1, num_features + 1):  # Iterate through each connected component\n",
        "            # Get the coordinates for each component\n",
        "            coords = np.argwhere(labeled_mask == i)\n",
        "\n",
        "            # Get the bounding box for the component\n",
        "            y_min, x_min = coords.min(axis=0)\n",
        "            y_max, x_max = coords.max(axis=0)\n",
        "\n",
        "            # Calculate the center of the component\n",
        "            center_y = (y_min + y_max) // 2\n",
        "            center_x = (x_min + x_max) // 2\n",
        "\n",
        "            # add a random offset between -128,128 pixels in the x-y direction\n",
        "\n",
        "            center_y = center_y + random.randint(-128,128)\n",
        "            center_x = center_x + random.randint(-128,128)\n",
        "\n",
        "            # Calculate the crop boundaries\n",
        "            y_start = max(0, center_y - target_size // 2)\n",
        "            y_end = min(image.shape[0], center_y + target_size // 2)\n",
        "            x_start = max(0, center_x - target_size // 2)\n",
        "            x_end = min(image.shape[1], center_x + target_size // 2)\n",
        "\n",
        "            # Adjust if cropping goes out of bounds\n",
        "            if (y_end - y_start < target_size) or (x_end - x_start < target_size):\n",
        "                # Handle the case where the crop exceeds the image boundaries\n",
        "                y_start = max(0, center_y - (target_size - (y_end - y_start)) // 2)\n",
        "                y_end = min(image.shape[0], center_y + (target_size - (y_end - y_start)) // 2)\n",
        "                x_start = max(0, center_x - (target_size - (x_end - x_start)) // 2)\n",
        "                x_end = min(image.shape[1], center_x + (target_size - (x_end - x_start)) // 2)\n",
        "\n",
        "            # Crop the pre-fire image using the adjusted boundaries\n",
        "            cropped_image = image[y_start:y_end, x_start:x_end]\n",
        "            cropped_mask = mask_fire_1[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            # If the crop size is smaller than target_size, pad it with zeros\n",
        "            if cropped_image.shape[0] < target_size or cropped_image.shape[1] < target_size:\n",
        "                padded_image = np.zeros((target_size, target_size), dtype=cropped_image.dtype)\n",
        "                padded_image[\n",
        "                    (target_size - cropped_image.shape[0]) // 2 : (target_size - cropped_image.shape[0]) // 2 + cropped_image.shape[0],\n",
        "                    (target_size - cropped_image.shape[1]) // 2 : (target_size - cropped_image.shape[1]) // 2 + cropped_image.shape[1]\n",
        "                ] = cropped_image\n",
        "                cropped_image = padded_image\n",
        "\n",
        "                # Similarly pad the cropped mask\n",
        "                padded_mask = np.zeros((target_size, target_size), dtype=cropped_mask.dtype)\n",
        "                padded_mask[\n",
        "                    (target_size - cropped_mask.shape[0]) // 2 : (target_size - cropped_mask.shape[0]) // 2 + cropped_mask.shape[0],\n",
        "                    (target_size - cropped_mask.shape[1]) // 2 : (target_size - cropped_mask.shape[1]) // 2 + cropped_mask.shape[1]\n",
        "                ] = cropped_mask\n",
        "                cropped_mask = padded_mask\n",
        "\n",
        "            # Display the cropped image and mask for each component\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "            # Show the cropped image\n",
        "            axes[0].imshow(cropped_image, cmap='gray')\n",
        "            axes[0].set_title(f\"Cropped Image - Region {i}\")\n",
        "            axes[0].axis('off')  # Hide axis\n",
        "\n",
        "            # Show the cropped mask image\n",
        "            axes[1].imshow(cropped_mask, cmap='gray')\n",
        "            axes[1].set_title(f\"Cropped Mask - Region {i}\")\n",
        "            axes[1].axis('off')  # Hide axis\n",
        "\n",
        "            plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "            plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"No regions found in the mask where the value is 1.\")\n"
      ],
      "metadata": {
        "id": "ZvOAoRzI-yy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the binary mask with red for active regions and transparent for inactive regions\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Use the 'Reds' colormap and set the alpha transparency based on the mask values\n",
        "plt.imshow(mask, cmap='Reds')  # Alpha will be 0 where mask is 0, 1 where mask is 1\n",
        "plt.title(\"Fire Mask in Red\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L4XkImsG-0UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALIZE\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Open the HDF5 file and load data\n",
        "with h5py.File('/content/drive/MyDrive/california_0.hdf5', 'r') as f:\n",
        "    # Access the group '0'\n",
        "    data = f['0']\n",
        "\n",
        "    # Access the first instance inside the group '0'\n",
        "    first_instance_key = list(data.keys())[0]\n",
        "    instance_1 = data[first_instance_key]\n",
        "\n",
        "    # Access 'pre_fire' data\n",
        "    pre_fire_1 = instance_1['pre_fire'][:]\n",
        "\n",
        "# Normalize function\n",
        "def normalize_image(img):\n",
        "    \"\"\"Normalize the input image to the range [0, 1].\"\"\"\n",
        "    img_min = np.min(img)\n",
        "    img_max = np.max(img)\n",
        "    if img_max - img_min == 0:\n",
        "        return np.zeros_like(img)  # Handle constant-valued images\n",
        "    return (img - img_min) / (img_max - img_min)\n",
        "\n",
        "# Example: Extract and normalize a specific channel\n",
        "channel_to_extract = 9  # Extract the 10th channel (index 9)\n",
        "original_channel = pre_fire_1[:, :, channel_to_extract]\n",
        "normalized_channel = normalize_image(original_channel)\n",
        "\n",
        "# Print the 2D arrays\n",
        "print(\"Original Channel (2D Array):\")\n",
        "print(original_channel)\n",
        "\n",
        "print(\"\\nNormalized Channel (2D Array):\")\n",
        "print(normalized_channel)\n",
        "\n",
        "\n",
        "print(f\"Original Channel - Min: {np.min(original_channel)}, Max: {np.max(original_channel)}\")\n",
        "print(f\"Normalized Channel - Min: {np.min(normalized_channel)}, Max: {np.max(normalized_channel)}\")\n",
        "\n",
        "\n",
        "# Display the original and normalized pre-fire image\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "axes[0].imshow(original_channel, cmap='gray')\n",
        "axes[0].set_title(f\"Original Pre-Fire Image - Channel {channel_to_extract + 1}\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "axes[1].imshow(normalized_channel, cmap='gray')\n",
        "axes[1].set_title(f\"Normalized Pre-Fire Image - Channel {channel_to_extract + 1}\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nuResdNd-zvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total number of pixels in the mask\n",
        "total_pixels = mask.size\n",
        "\n",
        "# Count the number of pixels that are 1 (indicating burned areas)\n",
        "active_pixels = np.sum(mask == 1)\n",
        "\n",
        "# Count the number of pixels that are 0 (indicating non-burned areas)\n",
        "inactive_pixels = np.sum(mask == 0)\n",
        "\n",
        "# Calculate the percentage of the image that is marked as burned\n",
        "percentage_burned = (active_pixels / total_pixels) * 100\n",
        "\n",
        "# Display the results\n",
        "print(f\"Total pixels: {total_pixels}\")\n",
        "print(f\"Active (burned) pixels: {active_pixels}\")\n",
        "print(f\"Inactive (non-burned) pixels: {inactive_pixels}\")\n",
        "print(f\"Percentage of the image burned: {percentage_burned:.2f}%\")"
      ],
      "metadata": {
        "id": "Tjv8bWK4-3Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Open each HDF5 file\n",
        "for i in range(10):\n",
        "    print (f\"Processing file {i}\")\n",
        "    with h5py.File(f'/content/drive/MyDrive/california_{i}.hdf5', 'r', ) as f:\n",
        "        # Get data from the group '0'\n",
        "        top_level_key = list(f.keys())[0]\n",
        "        if top_level_key == '0':\n",
        "            data = f['0']\n",
        "        else:\n",
        "            data = f\n",
        "\n",
        "        # Iterate over each instance in the group '0'\n",
        "        for instance_key in data.keys():\n",
        "            instance = data[instance_key]\n",
        "\n",
        "            # if mask is not present, skip\n",
        "            if 'mask' not in instance.keys():\n",
        "                continue\n",
        "\n",
        "            # Access the 'mask' data for the current instance\n",
        "            mask = instance['mask'][:]\n",
        "\n",
        "            # Calculate the total number of pixels in the mask\n",
        "            total_pixels = mask.size\n",
        "\n",
        "            # Count the number of pixels that are 1 (indicating burned areas)\n",
        "            active_pixels = np.sum(mask == 1)\n",
        "\n",
        "            # Count the number of pixels that are 0 (indicating non-burned areas)\n",
        "            inactive_pixels = np.sum(mask == 0)\n",
        "\n",
        "            # Calculate the percentage of the image that is marked as burned\n",
        "            percentage_burned = (active_pixels / total_pixels) * 100\n",
        "\n",
        "            # Display the results\n",
        "            print(f\"Total pixels: {total_pixels}\")\n",
        "            print(f\"Active (burned) pixels: {active_pixels}\")\n",
        "            print(f\"Inactive (non-burned) pixels: {inactive_pixels}\")\n",
        "            print(f\"Percentage of the image burned: {percentage_burned:.8f}%\\n\")"
      ],
      "metadata": {
        "id": "j10y_jFT-6Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten every channel in the pre-fire image\n",
        "flattened_image = pre_fire_1.reshape(-1, pre_fire_1.shape[-1])\n",
        "\n",
        "\n",
        "# Flatten the mask\n",
        "flattened_mask = mask.flatten()\n",
        "\n",
        "\n",
        "# Calculate the correlation between each of the channels and the mask\n",
        "correlations = np.corrcoef(flattened_image.T, flattened_mask)\n",
        "\n",
        "# Display the correlation coefficients for each channel\n",
        "print(\"Correlation Coefficients:\")\n",
        "for i, corr in enumerate(correlations[-1, :-1]):\n",
        "    print(f\"Channel {i + 1}: {corr:.4f}\")\n",
        "\n",
        "# Display correlation matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.colorbar()\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.xlabel(\"Channels\")\n",
        "plt.ylabel(\"Channels and Mask\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Cqddt2j7-78N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.measure import label\n",
        "%matplotlib inline\n",
        "\n",
        "# Function to normalize an image\n",
        "def normalize_image(img):\n",
        "    #Normalize the input image to the range [0, 1].\n",
        "    img_min = np.min(img)\n",
        "    img_max = np.max(img)\n",
        "    if img_max - img_min == 0:\n",
        "        return np.zeros_like(img)  # Handle constant-valued images\n",
        "    return (img - img_min) / (img_max - img_min)\n",
        "\n",
        "# Function to extract fire and non-fire patches\n",
        "def extract_patches(image, mask, target_size=512, num_non_fire_patches=25):\n",
        "    fire_patches = []\n",
        "    non_fire_patches = []\n",
        "\n",
        "    labeled_mask = label(mask)  # Label connected components in the mask\n",
        "    num_features = labeled_mask.max()  # Get the number of connected components\n",
        "\n",
        "    if num_features > 0:  # Check if any features were found\n",
        "        for i in range(1, num_features + 1):  # Iterate through each connected component (fire region)\n",
        "            coords = np.argwhere(labeled_mask == i)\n",
        "\n",
        "            if coords.size > 0:\n",
        "                print(f\"Processing fire region {i} at first coordinate: {coords[0]}\")\n",
        "\n",
        "            y_min, x_min = coords.min(axis=0)\n",
        "            y_max, x_max = coords.max(axis=0)\n",
        "            center_y = (y_min + y_max) // 2\n",
        "            center_x = (x_min + x_max) // 2\n",
        "\n",
        "            # Add random offset between -128, 128 pixels in the x-y direction\n",
        "            center_y += random.randint(-128, 128)\n",
        "            center_x += random.randint(-128, 128)\n",
        "\n",
        "            # Calculate crop boundaries\n",
        "            y_start = max(0, center_y - target_size // 2)\n",
        "            y_end = min(image.shape[0], center_y + target_size // 2)\n",
        "            x_start = max(0, center_x - target_size // 2)\n",
        "            x_end = min(image.shape[1], center_x + target_size // 2)\n",
        "\n",
        "            # Crop the image\n",
        "            cropped_image = image[y_start:y_end, x_start:x_end]\n",
        "            cropped_mask = mask[y_start:y_end, x_start:x_end]\n",
        "\n",
        "            # If the cropped area is smaller than target size, pad with zeros\n",
        "            if cropped_image.shape[0] < target_size or cropped_image.shape[1] < target_size:\n",
        "                print(f\"Padding image of shape {cropped_image.shape} to target size {target_size}\")\n",
        "                print(f\"Target center: ({center_y}, {center_x})\")\n",
        "                cropped_image = pad_image(cropped_image, target_size)\n",
        "                cropped_mask = pad_image(cropped_mask, target_size)\n",
        "\n",
        "            fire_patches.append((cropped_image, cropped_mask))\n",
        "\n",
        "            # Now collect num_non_fire_patches non-fire patches\n",
        "            non_fire_patches += get_non_fire_patches(image, mask, target_size, num_patches=num_non_fire_patches)\n",
        "\n",
        "    return fire_patches, non_fire_patches\n",
        "\n",
        "# Function to get non-fire patches\n",
        "def get_non_fire_patches(image, mask, target_size, num_patches):\n",
        "    non_fire_patches = []\n",
        "\n",
        "    while len(non_fire_patches) < num_patches:\n",
        "        i = np.random.randint(0, image.shape[0] - target_size)\n",
        "        j = np.random.randint(0, image.shape[1] - target_size)\n",
        "        patch = image[i:i+target_size, j:j+target_size]\n",
        "        patch_mask = mask[i:i+target_size, j:j+target_size]\n",
        "\n",
        "        if np.sum(patch_mask) == 0:  # No fire in the patch\n",
        "            non_fire_patches.append((patch, patch_mask))\n",
        "\n",
        "    return non_fire_patches\n",
        "\n",
        "# Function to pad images\n",
        "def pad_image(image, target_size):\n",
        "\n",
        "    if image.ndim == 2:\n",
        "        padded_image = np.zeros((target_size, target_size), dtype=image.dtype)\n",
        "        padded_image[\n",
        "            (target_size - image.shape[0]) // 2 : (target_size - image.shape[0]) // 2 + image.shape[0],\n",
        "            (target_size - image.shape[1]) // 2 : (target_size - image.shape[1]) // 2 + image.shape[1]\n",
        "        ] = image\n",
        "    else:\n",
        "        padded_image = np.zeros((target_size, target_size, image.shape[-1]), dtype=image.dtype)\n",
        "        padded_image[\n",
        "            (target_size - image.shape[0]) // 2 : (target_size - image.shape[0]) // 2 + image.shape[0],\n",
        "            (target_size - image.shape[1]) // 2 : (target_size - image.shape[1]) // 2 + image.shape[1],\n",
        "            :\n",
        "        ] = image\n",
        "    return padded_image\n",
        "\n",
        "# Functions to store patches in HDF5 file\n",
        "def append_to_dataset(hdf_file, dataset_name, data):\n",
        "    \"\"\"Append data to an existing dataset or create a new one if it doesn't exist.\"\"\"\n",
        "    if dataset_name in hdf_file:\n",
        "        dataset = hdf_file[dataset_name]\n",
        "        dataset.resize((dataset.shape[0] + data.shape[0]), axis=0)\n",
        "        dataset[-data.shape[0]:] = data\n",
        "    else:\n",
        "        maxshape = (None,) + data.shape[1:]\n",
        "        hdf_file.create_dataset(dataset_name, data=data, maxshape=maxshape)\n",
        "\n",
        "def store_patches_in_hdf5(fire_patches, non_fire_patches, instance_key, filename_prefix=\"fire_patches\"):\n",
        "    fire_images, fire_masks = zip(*fire_patches)\n",
        "    non_fire_images, non_fire_masks = zip(*non_fire_patches)\n",
        "\n",
        "    fire_images = np.array(fire_images)\n",
        "    fire_masks = np.array(fire_masks)\n",
        "    non_fire_images = np.array(non_fire_images)\n",
        "    non_fire_masks = np.array(non_fire_masks)\n",
        "\n",
        "    filename_prefix = f\"{filename_prefix}_{instance_key}.h5\"\n",
        "\n",
        "    with h5py.File(filename_prefix, 'a') as hdf_file:\n",
        "        append_to_dataset(hdf_file, \"fire_images\", fire_images)\n",
        "        append_to_dataset(hdf_file, \"fire_masks\", fire_masks)\n",
        "        append_to_dataset(hdf_file, \"non_fire_images\", non_fire_images)\n",
        "        append_to_dataset(hdf_file, \"non_fire_masks\", non_fire_masks)\n",
        "\n",
        "def augment_patch(image, mask, num_augmentations=5):\n",
        "\n",
        "    \"\"\"Apply random augmentation to the image and mask.\"\"\"\n",
        "    augmented_images = []\n",
        "    augmented_masks = []\n",
        "\n",
        "    augmented_images.append(image)\n",
        "    augmented_masks.append(mask)\n",
        "\n",
        "    for _ in range(num_augmentations):\n",
        "        augmented_image = np.copy(image)\n",
        "        augmented_mask = np.copy(mask)\n",
        "\n",
        "        # Flip horizontally\n",
        "        if random.random() > 0.5:\n",
        "            augmented_image = np.fliplr(augmented_image)\n",
        "            augmented_mask = np.fliplr(augmented_mask)\n",
        "\n",
        "        # Flip vertically\n",
        "        if random.random() > 0.5:\n",
        "            augmented_image = np.flipud(augmented_image)\n",
        "            augmented_mask = np.flipud(augmented_mask)\n",
        "\n",
        "        # Rotate by a random right angle\n",
        "        num_rotations = random.randint(0, 3)\n",
        "        augmented_image = np.rot90(augmented_image, num_rotations)\n",
        "        augmented_mask = np.rot90(augmented_mask, num_rotations)\n",
        "\n",
        "        augmented_images.append(augmented_image)\n",
        "        augmented_masks.append(augmented_mask)\n",
        "\n",
        "    return augmented_images, augmented_masks\n",
        "\n",
        "\n",
        "# Example pipeline execution\n",
        "def run_pipeline(hdf5_filename, instance_key='0'):\n",
        "    with h5py.File(hdf5_filename, 'r') as f:\n",
        "        # Access the first instance inside the group\n",
        "\n",
        "        #Special case for the first instance\n",
        "        top_level_key = list(f.keys())[0]\n",
        "        data = f\n",
        "\n",
        "        num_added_patches = 0\n",
        "\n",
        "        for key in data.keys():\n",
        "            # Access the instance\n",
        "            image = data[key]\n",
        "            print(f\"\\nProcessing instance: {key}\")\n",
        "\n",
        "            # Skip if the instance does not have the 'pre_fire' or 'mask' data\n",
        "            if 'pre_fire' not in image:\n",
        "                print(f\"Skipping instance {key} without 'pre_fire' data.\")\n",
        "                continue\n",
        "            if 'mask' not in image:\n",
        "                print(f\"Skipping instance {key} without 'mask' data.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            # Access image and mask data\n",
        "            pre_fire_1 = image['pre_fire'][:]\n",
        "            mask_fire_1 = image['mask'][:]\n",
        "\n",
        "             # Check the shape of pre_fire_1 to determine the channel position\n",
        "            if pre_fire_1.shape[0] == 12:\n",
        "                # Channels are in the first dimension\n",
        "                normalized_image = np.stack([normalize_image(pre_fire_1[i, :, :]) for i in range(pre_fire_1.shape[0])], axis=-1)\n",
        "                # Also flip the mask to match the image\n",
        "                mask_fire_1 = np.stack( [mask_fire_1[i, :, :] for i in range(mask_fire_1.shape[0])], axis=-1)\n",
        "                # Make the mask two dimensional, take it from (x,y,1) to (x,y)\n",
        "                mask_fire_1 = mask_fire_1[:,:,0]\n",
        "\n",
        "            else:\n",
        "                # Channels are in the last dimension\n",
        "                normalized_image = np.stack([normalize_image(pre_fire_1[:, :, i]) for i in range(pre_fire_1.shape[-1])], axis=-1)\n",
        "\n",
        "\n",
        "            # Extract patches\n",
        "            fire_patches, non_fire_patches = extract_patches(normalized_image, mask_fire_1)\n",
        "\n",
        "            # Display the number of patches extracted, and the different shapes present\n",
        "            print(f\"Number of fire patches: {len(fire_patches)}\")\n",
        "            print(f\"Number of non-fire patches: {len(non_fire_patches)}\")\n",
        "\n",
        "\n",
        "            # Augment fire patches only\n",
        "            augmented_fire_patches = []\n",
        "\n",
        "\n",
        "\n",
        "            for fire_image, fire_mask in fire_patches:\n",
        "                augmented_images, augmented_masks = augment_patch(fire_image, fire_mask)\n",
        "                augmented_fire_patches.extend(list(zip(augmented_images, augmented_masks)))\n",
        "\n",
        "\n",
        "            # Display the number of patches extracted, and the different shapes present\n",
        "            print(f\"Number of augmented fire patches: {len(augmented_fire_patches)}\")\n",
        "\n",
        "\n",
        "            # Store patches in an HDF5 file\n",
        "            store_patches_in_hdf5(augmented_fire_patches, non_fire_patches,  filename_prefix=\"fire_patches\", instance_key=instance_key)\n",
        "            num_added_patches += len(augmented_fire_patches)\n",
        "        print(f\"Number of patches attempted added in file {hdf5_filename}: {num_added_patches}\")\n",
        "        num_actual_added = 0\n",
        "        with h5py.File(f'fire_patches_{instance_key}.h5', 'r') as f:\n",
        "            num_actual_added = len(f['fire_images'])\n",
        "        print(f\"Number of patches actually added in file {hdf5_filename}: {num_actual_added}\")\n",
        "        return num_added_patches\n"
      ],
      "metadata": {
        "id": "8NwM4iba_BDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline for each california_{i}.hdf5 where i is in range(0, 10)\n",
        "num_augmented_images = 0\n",
        "for i in range(10):\n",
        "    print(f\"Running pipeline for california_{i}.hdf5\")\n",
        "    num_augmented_images += run_pipeline(f'/content/drive/california_{i}.hdf5', instance_key=f'{i}')\n",
        "    print(\"\\n\\n\\n\")\n",
        "print(f\"Total number of augmented images: {num_augmented_images}\")\n"
      ],
      "metadata": {
        "id": "pwYQTv7R_CH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect california_1.hdf5\n",
        "with h5py.File('california_1.hdf5', 'r') as f:\n",
        "    print(\"Keys: %s\" % list(f.keys()))\n",
        "    instance = f['0d30a00f-208f-4c9e-9aed-676527463854']\n",
        "    print(\"Keys inside instance: %s\" % list(instance.keys()))\n",
        "    pre_fire_1 = instance['pre_fire'][:]\n",
        "    print(\"Pre fire shape: %s\" % (pre_fire_1.shape,))\n",
        "    mask_1 = instance['mask'][:]\n",
        "\n",
        "    # For every key in the instance, print the value classes in each mask\n",
        "    for key in f.keys():\n",
        "        mask = f[key]['mask'][:]\n",
        "        print(f\"Mask Shape: {mask.shape}\")\n",
        "        print(f\"Mask {key} - Unique values: {np.unique(mask)}\")\n",
        "\n",
        "    # Display sample image from channel 10\n",
        "    plt.imshow(pre_fire_1[9, :, :], cmap='gray')\n",
        "    plt.title(\"Channel 10, 1-9 files\")\n",
        "    plt.show()\n",
        "\n",
        "    # Display the mask\n",
        "    plt.imshow(mask_1[0, :, :], cmap='Reds')\n",
        "    plt.title(\"Mask Image\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Inspect california_0.hdf5\n",
        "with h5py.File('california_0.hdf5', 'r') as f:\n",
        "    print(\"Keys: %s\" % list(f.keys()))\n",
        "    instance = f['0']\n",
        "    print(\"Keys inside instance: %s\" % list(instance.keys()))\n",
        "    first_key = list(instance.keys())[0]\n",
        "    pre_fire_1 = instance[first_key]['pre_fire'][:]\n",
        "    print(\"Pre fire shape: %s\" % (pre_fire_1.shape,))\n",
        "    mask = instance[first_key]['mask'][:]\n",
        "    print(f\"Mask Shape: {mask.shape}\")\n",
        "    print(f\"Mask - Unique values: {np.unique(mask)}\")\n",
        "\n",
        "    # Display sample image from channel 10\n",
        "    plt.imshow(pre_fire_1[:, :, 9], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    # Display the mask\n",
        "    plt.imshow(mask, cmap='Reds')\n",
        "    plt.title(\"Mask Image\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5GbHQ5o1_EIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly visually inspect 5 of the patches in a file\n",
        "with h5py.File('fire_patches_0.h5', 'r') as f:\n",
        "    fire_images = f['fire_images'][:]\n",
        "    fire_masks = f['fire_masks'][:]\n",
        "    non_fire_images = f['non_fire_images'][:]\n",
        "    non_fire_masks = f['non_fire_masks'][:]\n",
        "\n",
        "    # Randomly select 5 indices\n",
        "    indices = np.random.choice(len(fire_images), 5, replace=False)\n",
        "\n",
        "    # Display the images and masks\n",
        "    for i, idx in enumerate(indices):\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        # Display the dimensions of the images and masks\n",
        "        print(f\"Fire Image Shape: {fire_images[idx].shape}\")\n",
        "\n",
        "        # Show the fire image (channel 10) and mask\n",
        "        axes[0].imshow(fire_images[idx][:, :, 9], cmap='gray')  # Channel 10 is at index 9\n",
        "        axes[0].set_title(f\"Fire Image {i + 1} (Channel 10)\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(fire_masks[idx], cmap='gray')\n",
        "        axes[1].set_title(f\"Fire Mask {i + 1}\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        # Show the non-fire image (channel 10) and mask\n",
        "        axes[0].imshow(non_fire_images[idx][:, :, 9], cmap='gray')  # Channel 10 is at index 9\n",
        "        axes[0].set_title(f\"Non-Fire Image {i + 1} (Channel 10)\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(non_fire_masks[idx], cmap='gray')\n",
        "        axes[1].set_title(f\"Non-Fire Mask {i + 1}\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "R7dKvpyt_Nch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of fire patches and non-fire patches in the set of files fire_patches.h5_{i}.h5 for i in range(0, 10)\n",
        "\n",
        "num_fire_patches = 0\n",
        "num_non_fire_patches = 0\n",
        "\n",
        "for i in range(10):\n",
        "    filename = f'fire_patches_{i}.h5'\n",
        "    print(f\"Processing file: {filename}\")\n",
        "    with h5py.File(filename, 'r') as f:\n",
        "        print(f\"Shape of fire_images: {f['fire_images'].shape}\")\n",
        "        num_fire_patches += len(f['fire_images'])\n",
        "        print(f\"Number of fire patches: {len(f['fire_images'])}\")\n",
        "        num_non_fire_patches += len(f['non_fire_images'])\n",
        "\n",
        "print(f\"Total number of fire patches: {num_fire_patches}\")\n",
        "print(f\"Total number of non-fire patches: {num_non_fire_patches}\")"
      ],
      "metadata": {
        "id": "6tFsaS30_Poc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 2: Training the Model\n",
        "\n",
        "1.   Seeding\n",
        "2.   Initialization/Configuration\n",
        "3.   Convolutional Block\n",
        "4.   Encoder Block / Contracting Path\n",
        "5.   Decoder Block / Upsampling Path\n",
        "6.   Expansive Path - Skip Connections\n",
        "7.   Build U-Net\n",
        "8.   Initialize U-Net Model\n",
        "9.   Load Dataset\n",
        "10.  Training Callbacks\n",
        "11.  Data Visualization\n",
        "12.  Main (Put Everything together)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tFWqmcv46ROf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model specific imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, losses, metrics\n",
        "import h5py\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qaW-cliia9Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the UNet model\n",
        "\n",
        "def unet_model(input_size=(512, 512, 12)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder block 1\n",
        "    encoder0 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    encoder0 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(encoder0)\n",
        "    encoder1 = layers.MaxPooling2D((2, 2))(encoder0)  # Down to 256x256\n",
        "\n",
        "    # Encoder block 2\n",
        "    encoder1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(encoder1)\n",
        "    encoder1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(encoder1)\n",
        "    encoder2 = layers.MaxPooling2D((2, 2))(encoder1)  # Down to 128x128\n",
        "\n",
        "    # Encoder block 3\n",
        "    encoder2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(encoder2)\n",
        "    encoder2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(encoder2)\n",
        "    encoder3 = layers.MaxPooling2D((2, 2))(encoder2)  # Down to 64x64\n",
        "\n",
        "    # Encoder block 4\n",
        "    encoder3 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(encoder3)\n",
        "    encoder3 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(encoder3)\n",
        "    encoder4 = layers.MaxPooling2D((2, 2))(encoder3)  # Down to 32x32\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(encoder4)\n",
        "    bottleneck = layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(bottleneck)\n",
        "\n",
        "    # Decoder block 1\n",
        "    decoder3 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bottleneck)\n",
        "    decoder3 = layers.concatenate([decoder3, encoder3])  # Skip connection\n",
        "    decoder3 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(decoder3)\n",
        "    decoder3 = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(decoder3)\n",
        "\n",
        "    # Decoder block 2\n",
        "    decoder2 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(decoder3)\n",
        "    decoder2 = layers.concatenate([decoder2, encoder2])  # Skip connection\n",
        "    decoder2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(decoder2)\n",
        "    decoder2 = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(decoder2)\n",
        "\n",
        "    # Decoder block 3\n",
        "    decoder1 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(decoder2)\n",
        "    decoder1 = layers.concatenate([decoder1, encoder1])  # Skip connection\n",
        "    decoder1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(decoder1)\n",
        "    decoder1 = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(decoder1)\n",
        "\n",
        "    # Decoder block 4\n",
        "    decoder0 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(decoder1)\n",
        "    decoder0 = layers.concatenate([decoder0, encoder0])  # Skip connection\n",
        "    decoder0 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(decoder0)\n",
        "    decoder0 = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(decoder0)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "    # Build the model\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1aE_1cZKbBoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model = unet_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jons1nr_bDcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data, shuffle, and split into training and validation sets through a generator\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a Data Generator class with sorted indexing\n",
        "class HDF5DataGenerator(Sequence):\n",
        "    def __init__(self, hdf5_file, dataset_name, mask_name, batch_size=8, indices=None, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hdf5_file = hdf5_file\n",
        "        self.dataset_name = dataset_name\n",
        "        self.mask_name = mask_name\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # If indices are not provided, use the whole dataset\n",
        "        if indices is None:\n",
        "            with h5py.File(self.hdf5_file, 'r') as f:\n",
        "                self.indices = np.arange(len(f[self.dataset_name]))\n",
        "        else:\n",
        "            self.indices = indices\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of batches per epoch\n",
        "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generate batch indices\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Sort the indices to satisfy HDF5 indexing\n",
        "        sorted_batch_indices = np.sort(batch_indices)\n",
        "\n",
        "        # Open HDF5 file and load batch data\n",
        "        with h5py.File(self.hdf5_file, 'r') as f:\n",
        "            X_batch = f[self.dataset_name][sorted_batch_indices]\n",
        "            y_batch = f[self.mask_name][sorted_batch_indices]\n",
        "\n",
        "        # Reorder the batch according to the original shuffled batch_indices\n",
        "        reorder_indices = np.argsort(batch_indices)\n",
        "        X_batch = X_batch[reorder_indices]\n",
        "        y_batch = y_batch[reorder_indices]\n",
        "\n",
        "        # Convert to TensorFlow tensors\n",
        "        X_batch = tf.convert_to_tensor(X_batch)\n",
        "        y_batch = tf.convert_to_tensor(y_batch)\n",
        "\n",
        "        return X_batch, y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle the data at the end of each epoch if shuffle is True\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# Load dataset and split into train/validation sets using indices, not the actual data\n",
        "with h5py.File('fire_patches_0.h5', 'r') as hdf:\n",
        "    num_samples = len(hdf['fire_images'])\n",
        "\n",
        "# Generate train/test split indices instead of splitting actual data\n",
        "train_indices, val_indices = train_test_split(np.arange(num_samples), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Data Generators for training and validation, using indices for lazy loading\n",
        "train_generator = HDF5DataGenerator('fire_patches_0.h5', 'fire_images', 'fire_masks', batch_size=8, indices=train_indices, shuffle=True)\n",
        "val_generator = HDF5DataGenerator('fire_patches_0.h5', 'fire_images', 'fire_masks', batch_size=8, indices=val_indices, shuffle=False)\n",
        "\n",
        "# Verify the generators work and print the first batch shapes\n",
        "X_batch, y_batch = train_generator.__getitem__(0)\n",
        "print(f\"X_batch shape: {X_batch.shape}, y_batch shape: {y_batch.shape}\")"
      ],
      "metadata": {
        "id": "-mVLVKhzbErM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "rHGPHPXDbIf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "# Define callbacks (optional)\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Save the best model during training\n",
        "checkpoint = ModelCheckpoint('unet_wildfire.keras', monitor='loss', verbose=1, save_best_only=True)\n",
        "\n",
        "# Stop training if the loss doesn't improve for several epochs\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[checkpoint, early_stopping],\n",
        "    verbose=2  # Set verbosity to 2 for more detailed output\n",
        ")"
      ],
      "metadata": {
        "id": "KKe6XdwsbJ_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "mETOz42RbLPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the fire prediction mask\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Function to visualize the prediction mask as a red-scale heatmap over the prefire image channel 10\n",
        "def visualize_prediction(image, prediction_mask, channel=10):\n",
        "    # Extract the prefire image channel 10\n",
        "    prefire_channel = image[:, :, channel]\n",
        "\n",
        "    # Create a red-scale heatmap from the prediction mask\n",
        "    heatmap = np.zeros_like(image)\n",
        "    heatmap[:, :, 0] = prediction_mask * 255  # Red channel\n",
        "    heatmap[:, :, 1] = 0  # Green channel\n",
        "    heatmap[:, :, 2] = 0  # Blue channel\n",
        "\n",
        "    # Overlay the heatmap on the prefire image channel 10\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    ax[0].imshow(prefire_channel, cmap='gray')\n",
        "    ax[0].set_title('Prefire Image Channel 10')\n",
        "    ax[1].imshow(prefire_channel, cmap='gray')\n",
        "    ax[1].imshow(heatmap, cmap='Reds', alpha=0.5)\n",
        "    ax[1].set_title('Prediction Heatmap Overlay')\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the predictions for a few test images\n",
        "for i in range(5):\n",
        "    visualize_prediction(X_test[i], predictions[i])"
      ],
      "metadata": {
        "id": "M_1Sah3vbMSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}